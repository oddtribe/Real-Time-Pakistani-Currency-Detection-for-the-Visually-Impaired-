{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/ammar/Desktop/U/semester-8/fyp/data-rescaled-split/train'\n",
    "test_dir = '/home/ammar/Desktop/U/semester-8/fyp/data-rescaled-split/test'\n",
    "val_dir = '/home/ammar/Desktop/U/semester-8/fyp/data-rescaled-split/val'\n",
    "visualization_dir = '/home/ammar/Desktop/U/semester-8/fyp/data-rescaled-split/augmented'  # For storing augmented images generated in a directory\n",
    "log_dir = '/home/ammar/Desktop/U/semester-8/fyp/data-rescaled-split/logs'  # For stroing tensorboard logs\n",
    "\n",
    "image_height = 224\n",
    "image_width  = 224\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3746 images belonging to 15 classes.\n",
      "Found 410 images belonging to 15 classes.\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.9445 - accuracy: 0.7274 - precision: 0.9477 - val_loss: 0.7954 - val_accuracy: 0.7659 - val_precision: 0.8125\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 213s 2s/step - loss: 0.1817 - accuracy: 0.9562 - precision: 0.9761 - val_loss: 0.5378 - val_accuracy: 0.8220 - val_precision: 0.8508\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 209s 2s/step - loss: 0.1142 - accuracy: 0.9701 - precision: 0.9819 - val_loss: 0.3539 - val_accuracy: 0.8951 - val_precision: 0.9191\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 192s 2s/step - loss: 0.0835 - accuracy: 0.9784 - precision: 0.9840 - val_loss: 0.1725 - val_accuracy: 0.9415 - val_precision: 0.9547\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 187s 2s/step - loss: 0.0725 - accuracy: 0.9789 - precision: 0.9846 - val_loss: 0.2196 - val_accuracy: 0.9341 - val_precision: 0.9471\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 179s 2s/step - loss: 0.0520 - accuracy: 0.9872 - precision: 0.9914 - val_loss: 0.1238 - val_accuracy: 0.9610 - val_precision: 0.9724\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 203s 2s/step - loss: 0.0593 - accuracy: 0.9837 - precision: 0.9870 - val_loss: 0.1954 - val_accuracy: 0.9415 - val_precision: 0.9622\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 176s 1s/step - loss: 0.0447 - accuracy: 0.9875 - precision: 0.9901 - val_loss: 0.1634 - val_accuracy: 0.9463 - val_precision: 0.9599\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 178s 2s/step - loss: 0.0564 - accuracy: 0.9842 - precision: 0.9884 - val_loss: 0.1542 - val_accuracy: 0.9463 - val_precision: 0.9626\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 177s 1s/step - loss: 0.0382 - accuracy: 0.9883 - precision: 0.9898 - val_loss: 0.1403 - val_accuracy: 0.9512 - val_precision: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cc45902e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    # constructing the model\n",
    "    model = applications.MobileNetV3Large(weights=\"imagenet\", include_top=False, input_shape=(image_width, image_height, 3),\n",
    "                                  pooling='avg')\n",
    "\n",
    "    # We don't want 10 layers from last, practice of transfer learning\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Adding custom Layers\n",
    "    x = model.output\n",
    "    \n",
    "    predictions = Dense(15, activation=\"softmax\")(x)   # Connecting our required output layer with the MobileNet\n",
    "\n",
    "    # creating the final model\n",
    "    model_final = Model(inputs=model.input, outputs=predictions)   \n",
    "    \n",
    "    return model_final\n",
    "\n",
    "model_final = build_model()\n",
    "\n",
    "# compile the model\n",
    "model_final.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=optimizers.Adam(learning_rate=0.001),  # Adam gives better results on this learning rate\n",
    "                    metrics=[\"accuracy\", \"Precision\"])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    fill_mode=\"nearest\",   # If any pixels are empty should fill using this method\n",
    "    zoom_range=0.2,        # Number greater than 0.2 would give unwanted augmented images\n",
    "    width_shift_range = 0.2,    # Number greater than 0.2 would give unwanted augmented images\n",
    "    height_shift_range = 0.2,    # Number greater than 0.2 would give unwanted augmented images\n",
    "    shear_range = 0.2,          # Number greater than 0.2 would give unwanted augmented images\n",
    "    rotation_range=180\n",
    ")\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    \n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    save_to_dir = visualization_dir,\n",
    "    target_size=(image_height, image_width),  \n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\")  # As we want multuple categories\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir)  # Tensorboard callback used for plotting\n",
    "\n",
    "# Train the model\n",
    "model_final.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 455 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Now evaluating our model on test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    fill_mode=\"nearest\",\n",
    "    zoom_range=0.3,\n",
    "    rotation_range=30\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                    test_dir,\n",
    "                    target_size=(image_height, image_width),\n",
    "                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 862ms/step - loss: 0.1388 - accuracy: 0.9495 - precision: 0.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1388421654701233, 0.9494505524635315, 0.951434850692749]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fifth-data-augmented-background-model.hd5/assets\n"
     ]
    }
   ],
   "source": [
    "model_final.save('fifth-data-augmented-background-model.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000_back': 0,\n",
       " '1000_front': 1,\n",
       " '100_back': 2,\n",
       " '100_front': 3,\n",
       " '10_back': 4,\n",
       " '10_front': 5,\n",
       " '20_back': 6,\n",
       " '20_front': 7,\n",
       " '5000_back': 8,\n",
       " '5000_front': 9,\n",
       " '500_back': 10,\n",
       " '500_front': 11,\n",
       " '50_back': 12,\n",
       " '50_front': 13,\n",
       " 'background': 14}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
